# DanceGPT2

Welcome to DanceGPT2.

This repository contains code for training a GPT-2 model to unconditionally generate dance music. By leveraging the high fidelity neural audio compression codec, EnCodec, audio is converted into a set of codes which are then fed to the GPT-2 Transformer. After training, the model can create new dance music tracks.

## Overview

The project focuses on generating dance music using the following workflow:
1. **Audio Compression**: Using the EnCodec codec to convert audio files into a compressed format.
2. **Training GPT-2**: Training the GPT-2 model on the compressed audio data.
3. **Music Generation (Inference)**: Prompting the trained GPT-2 model to generate new dance music tracks.

## Repository Contents

- `training_notebook.ipynb`: A Jupyter notebook containing the full training pipeline for the GPT-2 model.
- `longer_audio_samples/`: A folder with long audio samples generated by the model.

The model is capable of generating longer examples as well as continuing existing music, providing flexibility in music creation and extension.
